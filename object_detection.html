<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Object Detection On Browser</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js"></script>

    <style>
        body,
        html {
            height: 100%;
            margin: 0;
            display: flex;
            flex-direction: column;
            justify-content: center;
            align-items: center;
            font-family: Arial, sans-serif;
        }

        #header {
            position: absolute;
            z-index: 2;
            top: 0px;
            width: 100%;
            text-align: center;
            background: rgba(255, 255, 255, 0.9);
            padding: 10px 0;
        }

        #controls {
            position: absolute;
            top: 120px;
            z-index: 3;
            text-align: center;
            background: rgba(255, 255, 255, 0.9);
            padding: 10px;
            border-radius: 5px;
        }

        #main {
            position: relative;
            width: 640px;
            height: 480px;
            margin-top: 50px;
        }

        #webcam,
        #imageDisplay,
        #outputCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        #imageDisplay {
            object-fit: contain;
            display: none;
        }

        #outputCanvas {
            z-index: 2;
            pointer-events: none;
        }

        button {
            font-size: 16px;
            background-color: #000;
            color: #fff;
            cursor: pointer;
            margin: 5px;
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
        }

        button:hover {
            background-color: #333;
        }

        button:disabled {
            background-color: #666;
            cursor: not-allowed;
        }

        #fileInput {
            margin: 10px;
        }

        .mode-selector {
            margin: 10px 0;
        }

        .mode-selector label {
            margin: 0 10px;
            font-weight: bold;
        }

        #status {
            margin-top: 10px;
            padding: 10px;
            background: rgba(0, 0, 0, 0.1);
            border-radius: 5px;
            min-height: 20px;
        }
    </style>
</head>

<body>
    <div id="header">
        <h1>YOLOv8 Object Detection </h1>
    </div>
    
    <div id="controls">
        <div class="mode-selector">
            <label>
                <input type="radio" name="mode" value="webcam" checked> Webcam
            </label>
            <label>
                <input type="radio" name="mode" value="image"> Image Upload
            </label>
        </div>
        
        <div id="webcam-controls">
            <button id="runInference">Start Webcam Detection</button>
            <button id="stopInference" disabled>Stop Detection</button>
        </div>
        
        <div id="image-controls" style="display: none;">
            <input type="file" id="fileInput" accept="image/*">
            <button id="detectImage" disabled>Detect Objects</button>
        </div>
        
        <div id="status">Select mode and click start to begin detection</div>
    </div>
    
    <div id="main">
        <video id="webcam" autoplay playsinline width="640" height="480"></video>
        <img id="imageDisplay" alt="Uploaded image">
        <canvas id="outputCanvas"></canvas>
    </div>

    <script>
        const classNames = {
            0: "person",1: "bicycle", 2: "car", 3: "motorcycle", 4: "airplane", 5: "bus",6: "train",7: "truck",8: "boat",9: "traffic light",10: "fire hydrant",
            11: "stop sign",12: "parking meter",13: "bench",14: "bird",15: "cat",16: "dog",17: "horse",18: "sheep",19: "cow",20: "elephant",
            21: "bear",22: "zebra",23: "giraffe",24: "backpack",25: "umbrella",26: "handbag",27: "tie",28: "suitcase",29: "frisbee",30: "skis",
            31: "snowboard",32: "sports ball",33: "kite",34: "baseball bat",35: "baseball glove",36: "skateboard",37: "surfboard",38: "tennis racket",39: "bottle",40: "wine glass",
            41: "cup",42: "fork",43: "knife",44: "spoon",45: "bowl",46: "banana",47: "apple",48: "sandwich",49: "orange",50: "broccoli",
            51: "carrot",52: "hot dog",53: "pizza",54: "donut",55: "cake",56: "chair",57: "couch",58: "potted plant",59: "bed",60: "dining table",
            61: "toilet",62: "tv",63: "laptop",64: "mouse",65: "remote",66: "keyboard",67: "cell phone",68: "microwave",69: "oven",70: "toaster",
            71: "sink",72: "refrigerator",73: "book",74: "clock",75: "vase",76: "scissors",77: "teddy bear",78: "hair drier",79: "toothbrush"
        };

        const TARGET_WIDTH = 640;
        const TARGET_HEIGHT = 640;
        let model;
        let intervalId;
        let currentMode = 'webcam';

       
        const webcamControls = document.getElementById('webcam-controls');
        const imageControls = document.getElementById('image-controls');
        const fileInput = document.getElementById('fileInput');
        const detectImageBtn = document.getElementById('detectImage');
        const runInferenceBtn = document.getElementById('runInference');
        const stopInferenceBtn = document.getElementById('stopInference');
        const statusDiv = document.getElementById('status');
        const webcamElement = document.getElementById('webcam');
        const imageElement = document.getElementById('imageDisplay');
        const modeRadios = document.querySelectorAll('input[name="mode"]');

        async function loadModel() {
            if (model) return;
            
            updateStatus('Loading model...');
            try {
                tf.setBackend('webgl');
                model = await tf.loadGraphModel('yolov8n_web_model/model.json');
                updateStatus('Model loaded successfully!');
            } catch (error) {
                updateStatus('Error loading model: ' + error.message);
                console.error('Model loading error:', error);
            }
        }

        async function runModel(tensor) {
            if (!model) await loadModel();
            return model.predict(tensor);
        }

        function updateStatus(message) {
            statusDiv.textContent = message;
        }

        modeRadios.forEach(radio => {
            radio.addEventListener('change', (e) => {
                currentMode = e.target.value;
                switchMode(currentMode);
            });
        });

        function switchMode(mode) {
            if (mode === 'webcam') {
                webcamControls.style.display = 'block';
                imageControls.style.display = 'none';
                webcamElement.style.display = 'block';
                imageElement.style.display = 'none';
                updateStatus('Webcam mode selected');
            } else {
                webcamControls.style.display = 'none';
                imageControls.style.display = 'block';
                webcamElement.style.display = 'none';
                imageElement.style.display = 'block';
                updateStatus('Image mode selected');
                stopWebcamDetection();
            }
            clearCanvas();
        }

        
        async function processWebcamFrame() {
            try {
                const tensor = await webcamToTensor(webcamElement);
                const startTime = performance.now();
                const predictions = await runModel(tensor);
                const endTime = performance.now();
                const inferenceTime = endTime - startTime;
                
                const detections = processPredictions(predictions, classNames);
                await drawBoundingBoxes(webcamElement, detections);
                
                updateStatus(`Inference Time: ${inferenceTime.toFixed(2)} ms | Objects: ${detections.length}`);
            } catch (error) {
                updateStatus('Error processing frame: ' + error.message);
                console.error('Frame processing error:', error);
            }
        }

        async function setupWebcam() {
            if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    webcamElement.srcObject = stream;
                    updateStatus('Webcam initialized');
                } catch (error) {
                    updateStatus('Error accessing webcam: ' + error.message);
                    console.error('Webcam setup error:', error);
                }
            } else {
                updateStatus('getUserMedia is not supported');
            }
        }

        function startWebcamDetection() {
            if (intervalId) return;
            intervalId = setInterval(processWebcamFrame, 100);
            runInferenceBtn.disabled = true;
            stopInferenceBtn.disabled = false;
            updateStatus('Webcam detection started');
        }

        function stopWebcamDetection() {
            if (intervalId) {
                clearInterval(intervalId);
                intervalId = null;
                runInferenceBtn.disabled = false;
                stopInferenceBtn.disabled = true;
                updateStatus('Webcam detection stopped');
            }
        }

       
        async function processImageFile(file) {
            return new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onload = (e) => {
                    const img = new Image();
                    img.onload = () => resolve(img);
                    img.onerror = reject;
                    img.src = e.target.result;
                };
                reader.onerror = reject;
                reader.readAsDataURL(file);
            });
        }

        async function detectObjectsInImage() {
            const file = fileInput.files[0];
            if (!file) {
                updateStatus('Please select an image file');
                return;
            }

            try {
                updateStatus('Processing image...');
                const img = await processImageFile(file);
                
               
                imageElement.src = img.src;
                imageElement.style.display = 'block';
                
                
                const tensor = await imageToTensor(img);
                const startTime = performance.now();
                const predictions = await runModel(tensor);
                const endTime = performance.now();
                const inferenceTime = endTime - startTime;
                
                const detections = processPredictions(predictions, classNames);
                await drawBoundingBoxes(imageElement, detections);
                
                updateStatus(`Inference Time: ${inferenceTime.toFixed(2)} ms | Objects detected: ${detections.length}`);
            } catch (error) {
                updateStatus('Error processing image: ' + error.message);
                console.error('Image processing error:', error);
            }
        }

        async function imageToTensor(imageElement) {
            const canvas = document.createElement('canvas');
            canvas.width = TARGET_WIDTH;
            canvas.height = TARGET_HEIGHT;
            const ctx = canvas.getContext('2d', { willReadFrequently: true });

            ctx.drawImage(imageElement, 0, 0, TARGET_WIDTH, TARGET_HEIGHT);
            const imageData = ctx.getImageData(0, 0, TARGET_WIDTH, TARGET_HEIGHT);
            const tensor = tf.browser.fromPixels(imageData);

            return tf.cast(tensor, 'float32').div(tf.scalar(255)).expandDims(0);
        }

     
        function extractSelectedPredictions(indices, boxes, labels, classNames) {
            return indices.map(i => {
                const box = boxes.slice([i, 0], [1, -1]).squeeze().arraySync();
                const label = labels.slice([i], [1]).arraySync()[0];
                return { box, label: classNames[label] };
            });
        }

        async function webcamToTensor(videoElement) {
            const canvas = document.createElement('canvas');
            canvas.width = TARGET_WIDTH;
            canvas.height = TARGET_HEIGHT;
            const ctx = canvas.getContext('2d', { willReadFrequently: true });

            ctx.drawImage(videoElement, 0, 0, TARGET_WIDTH, TARGET_HEIGHT);
            const imageData = ctx.getImageData(0, 0, TARGET_WIDTH, TARGET_HEIGHT);
            const tensor = tf.browser.fromPixels(imageData);

            return tf.cast(tensor, 'float32').div(tf.scalar(255)).expandDims(0);
        }

        function processPredictions(predictions, classNames) {
            return tf.tidy(() => {
                const transRes = predictions.transpose([0, 2, 1]);
                const boxes = calculateBoundingBoxes(transRes);
                const [scores, labels] = calculateScoresAndLabels(transRes, classNames);

                const indices = tf.image.nonMaxSuppression(boxes, scores, predictions.shape[2], 0.45, 0.2).arraySync();
                return extractSelectedPredictions(indices, boxes, labels, classNames);
            });
        }

        function calculateBoundingBoxes(transRes) {
            const [xCenter, yCenter, width, height] = [
                transRes.slice([0, 0, 0], [-1, -1, 1]),
                transRes.slice([0, 0, 1], [-1, -1, 1]),
                transRes.slice([0, 0, 2], [-1, -1, 1]),
                transRes.slice([0, 0, 3], [-1, -1, 1])
            ];

            const topLeftX = tf.sub(xCenter, tf.div(width, 2));
            const topLeftY = tf.sub(yCenter, tf.div(height, 2));
            return tf.concat([topLeftX, topLeftY, width, height], 2).squeeze();
        }

        function calculateScoresAndLabels(transRes, classNames) {
            const rawScores = transRes.slice([0, 0, 4], [-1, -1, Object.keys(classNames).length]).squeeze(0);
            return [rawScores.max(1), rawScores.argMax(1)];
        }

        async function drawBoundingBoxes(imageElement, detections) {
            const canvas = document.getElementById('outputCanvas');
            const ctx = canvas.getContext('2d', { willReadFrequently: true });
            canvas.width = imageElement.width || imageElement.videoWidth;
            canvas.height = imageElement.height || imageElement.videoHeight;
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            const resizeScale = Math.min(TARGET_WIDTH / canvas.width, TARGET_HEIGHT / canvas.height);
            const dx = (TARGET_WIDTH - canvas.width * resizeScale) / 2;
            const dy = (TARGET_HEIGHT - canvas.height * resizeScale) / 2;

            detections.forEach(({ box, label }) => {
                let [topLeftX, topLeftY, width, height] = box;
                topLeftX = topLeftX / resizeScale - dx / resizeScale;
                topLeftY = topLeftY / resizeScale - dy / resizeScale;
                width /= resizeScale;
                height /= resizeScale;

                ctx.strokeStyle = 'red';
                ctx.lineWidth = 2;
                ctx.strokeRect(topLeftX, topLeftY, width, height);
                ctx.fillStyle = 'red';
                ctx.font = '20px Arial';
                ctx.fillText(label, topLeftX, topLeftY - 7);
            });
        }

        function clearCanvas() {
            const canvas = document.getElementById('outputCanvas');
            const ctx = canvas.getContext('2d');
            ctx.clearRect(0, 0, canvas.width, canvas.height);
        }

        
        runInferenceBtn.addEventListener('click', async () => {
            await loadModel();
            await setupWebcam();
            startWebcamDetection();
        });

        stopInferenceBtn.addEventListener('click', stopWebcamDetection);

        fileInput.addEventListener('change', (e) => {
            detectImageBtn.disabled = !e.target.files[0];
        });

        detectImageBtn.addEventListener('click', async () => {
            await loadModel();
            await detectObjectsInImage();
        });

       
        switchMode('webcam');
    </script>
</body>

</html>